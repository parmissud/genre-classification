{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9JYjiK3XvgT",
        "outputId": "9e9a09f8-fe31-42a1-8a45-d1ccb0355e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">\n",
        "    این دستور برای نصب کتابخانه‌های transformers، torch، و scikit-learn استفاده می‌شود. این کتابخانه‌ها برای کار با مدل‌های پردازش زبان طبیعی، شبکه‌های عصبی و ابزارهای یادگیری ماشین استفاده می‌شوند.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EJCj__KuY4zs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = pd.read_csv('/content/dataTrain.csv')\n",
        "\n",
        "test_df = pd.read_csv('/content/testTrain.csv')\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">توضیح: ابتدا کتابخانه‌های pandas و train_test_split از scikit-learn بارگذاری می‌شوند. سپس داده‌ها از فایل‌های CSV خوانده می‌شوند. داده‌ها به دو مجموعه آموزشی و اعتبارسنجی تقسیم می‌شوند.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ltx-aK_YY6YC"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def encode_data(text_list, max_length=512):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        text_list,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "train_encodings = encode_data(train_df['description'].tolist())\n",
        "val_encodings = encode_data(val_df['description'].tolist())\n",
        "test_encodings = encode_data(test_df['description'].tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">توضیح: کتابخانه DistilBertTokenizer از transformers بارگذاری می‌شود. یک تابع encode_data برای توکنایز کردن متن‌ها ایجاد می‌شود. این تابع متن‌ها را به توکن‌ها تبدیل می‌کند و آن‌ها را به فرمت مناسب برای مدل BERT آماده می‌کند. سپس داده‌های آموزشی، اعتبارسنجی و تست توکنایز می‌شوند.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UzzumV7bY9Sq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MovieDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_labels = train_df['genre'].astype('category').cat.codes.tolist()\n",
        "val_labels = val_df['genre'].astype('category').cat.codes.tolist()\n",
        "test_labels = test_df['genre'].astype('category').cat.codes.tolist()\n",
        "\n",
        "train_dataset = MovieDataset(train_encodings, train_labels)\n",
        "val_dataset = MovieDataset(val_encodings, val_labels)\n",
        "test_dataset = MovieDataset(test_encodings, test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">کتابخانه‌های torch و DataLoader بارگذاری می‌شوند. یک کلاس MovieDataset ایجاد می‌شود که داده‌های توکنایز شده و برچسب‌ها را مدیریت می‌کند. سپس برچسب‌ها به کدهای دسته‌بندی تبدیل شده و Datasetهای آموزشی، اعتبارسنجی و تست ایجاد می‌شوند.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z0cIPmWxY-3D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeE1x78yZA-S",
        "outputId": "fdf929f8-35f1-4f67-ae2e-c759818fd03d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# Load DistilBERT model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=train_df['genre'].nunique())\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">\n",
        "توضیح: کتابخانه‌های DistilBertForSequenceClassification, AdamW, و get_linear_schedule_with_warmup از transformers بارگذاری می‌شوند. مدل DistilBERT برای دسته‌بندی توالی‌ها بارگذاری می‌شود. اگر GPU موجود باشد، مدل به دستگاه CUDA منتقل می‌شود. سپس DataLoader برای مجموعه‌های داده‌های آموزشی و اعتبارسنجی ایجاد می‌شود. بهینه‌ساز AdamW و تنظیم‌کننده یادگیری خطی تنظیم می‌شوند.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtrEZ8chZCKS",
        "outputId": "a4485b44-2d6a-441c-9f1e-f8ee3d26c348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 5080/5080 [32:51<00:00,  2.58it/s, accuracy=tensor(0.6130, device='cuda:0', dtype=torch.float64), loss=1.3]\n",
            "Evaluating: 100%|██████████| 565/565 [01:14<00:00,  7.57it/s, accuracy=tensor(0.6597, device='cuda:0', dtype=torch.float64), loss=1.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 1.302177163436422, accuracy 0.6131072500861348\n",
            "Validation loss 1.0941453255647051, accuracy 0.6604651162790698\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 5080/5080 [32:52<00:00,  2.58it/s, accuracy=tensor(0.7294, device='cuda:0', dtype=torch.float64), loss=0.885]\n",
            "Evaluating: 100%|██████████| 565/565 [01:14<00:00,  7.58it/s, accuracy=tensor(0.6748, device='cuda:0', dtype=torch.float64), loss=1.07]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.8852045568058223, accuracy 0.729487621203918\n",
            "Validation loss 1.065812353024968, accuracy 0.6755260243632337\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 5080/5080 [32:52<00:00,  2.58it/s, accuracy=tensor(0.8135, device='cuda:0', dtype=torch.float64), loss=0.634]\n",
            "Evaluating: 100%|██████████| 565/565 [01:14<00:00,  7.59it/s, accuracy=tensor(0.6808, device='cuda:0', dtype=torch.float64), loss=1.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.6335652845413021, accuracy 0.8136535905891619\n",
            "Validation loss 1.1027447583664836, accuracy 0.6815060908084164\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "total_steps = len(train_loader) * 3\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(**inputs, labels=labels)  \n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix(loss=total_loss / len(progress_bar), accuracy=correct_predictions.double() / (len(progress_bar) * data_loader.batch_size))\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), total_loss / len(data_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def eval_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    progress_bar = tqdm(data_loader, desc=\"Evaluating\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(**inputs, labels=labels)  \n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_postfix(loss=total_loss / len(progress_bar), accuracy=correct_predictions.double() / (len(progress_bar) * data_loader.batch_size))\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), total_loss / len(data_loader)\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
        "    val_acc, val_loss = eval_model(model, val_loader, device)\n",
        "    print(f'Train loss {train_loss}, accuracy {train_acc}')\n",
        "    print(f'Validation loss {val_loss}, accuracy {val_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">\n",
        "توضیح: دو تابع train_epoch و eval_model برای آموزش و ارزیابی مدل ایجاد می‌شوند. این توابع داده‌ها را به مدل ورودی می‌دهند و دقت و خطای مدل را محاسبه می‌کنند.\n",
        "\n",
        "حلقه آموزشی برای سه دوره تنظیم شده است. در هر دوره، مدل آموزش داده شده و بر روی داده‌های اعتبارسنجی ارزیابی می‌شود. دقت و خطای مدل برای هر دوره چاپ می‌شود.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "huio20hUZDuT"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'distilbert_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teIa3G_kZEii",
        "outputId": "d8c93673-4029-43af-8935-209e711c6a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/distilbert_model.pth'\n",
        "\n",
        "torch.save(model, drive_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6OVA7bZGA7",
        "outputId": "005ac7e8-76a8-41a5-b93a-ae8bc228361b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|██████████| 996/996 [02:01<00:00,  8.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            description         genre  \\\n",
            "0      Sandro is a well-known journalist and he is c...        comedy   \n",
            "1      A young boys life is changed when he's kidnap...         short   \n",
            "2      On the coast of Yugoslavia lives fisherman Iv...         drama   \n",
            "3      Crime TV show that is a mosaic of individual ...         crime   \n",
            "4      Adam is a lost soul. He has lost his girlfrie...         short   \n",
            "...                                                 ...           ...   \n",
            "7963   Patrick O\"Neal narrates this 'nostalgic' look...   documentary   \n",
            "7964   Montmartre in the summertime. A group of stre...        comedy   \n",
            "7965   \"Bar Rescue\" heads \"Back to the Bar\" to check...    reality-tv   \n",
            "7966   The son of a Swedish man murdered in Germany ...   documentary   \n",
            "7967   On air news reporter Robin Taylor several vid...        horror   \n",
            "\n",
            "     predicted_genre  \n",
            "0              drama  \n",
            "1          adventure  \n",
            "2              drama  \n",
            "3              crime  \n",
            "4              short  \n",
            "...              ...  \n",
            "7963     documentary  \n",
            "7964          comedy  \n",
            "7965      reality-tv  \n",
            "7966           drama  \n",
            "7967        thriller  \n",
            "\n",
            "[7968 rows x 3 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "def predict(model, data_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "\n",
        "    progress_bar = tqdm(data_loader, desc=\"Predicting\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "    return preds\n",
        "\n",
        "test_preds = predict(model, test_loader, device)\n",
        "\n",
        "\n",
        "genre_mapping = dict(enumerate(test_df['genre'].astype('category').cat.categories))\n",
        "predicted_genres = [genre_mapping[p] for p in test_preds]\n",
        "\n",
        "test_df['predicted_genre'] = predicted_genres\n",
        "\n",
        "print(test_df[['description', 'genre', 'predicted_genre']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div style=\"direction: rtl; text-align: right; font-family: 'B Nazanin', 'Arial', sans-serif;\">\n",
        "توضیح: داده‌های تست به مدل ورودی داده می‌شوند و پیش‌بینی‌ها انجام می‌شود. سپس نتایج پیش‌بینی شده با برچسب‌های واقعی مقایسه می‌شوند.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsdfYIdnZH67",
        "outputId": "babb81f7-5070-4fb4-d308-3eb55b53b0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6676706827309237\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "accuracy = np.sum(test_df['genre'] == test_df['predicted_genre']) / len(test_df)\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
